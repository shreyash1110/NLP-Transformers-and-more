{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Importing necessary libraries"
      ],
      "metadata": {
        "id": "AsVjzHfQebJb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EkTYv_3beXNJ"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from nltk.corpus import reuters\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = reuters.words()\n",
        "words = [word.lower() for word in words]\n",
        "# also remove any punctuation marks present\n",
        "words = [word for word in words if word.isalpha()]"
      ],
      "metadata": {
        "id": "QKLAVpgYjWuu"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words[0:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoVMm9nrjkVb",
        "outputId": "21d5edd5-a3ce-4b71-d51e-30907e4c936b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['asian',\n",
              " 'exporters',\n",
              " 'fear',\n",
              " 'damage',\n",
              " 'from',\n",
              " 'u',\n",
              " 's',\n",
              " 'japan',\n",
              " 'rift',\n",
              " 'mounting',\n",
              " 'trade',\n",
              " 'friction',\n",
              " 'between',\n",
              " 'the',\n",
              " 'u',\n",
              " 's',\n",
              " 'and',\n",
              " 'japan',\n",
              " 'has',\n",
              " 'raised',\n",
              " 'fears',\n",
              " 'among',\n",
              " 'many',\n",
              " 'of',\n",
              " 'asia',\n",
              " 's',\n",
              " 'exporting',\n",
              " 'nations',\n",
              " 'that',\n",
              " 'the',\n",
              " 'row',\n",
              " 'could',\n",
              " 'inflict',\n",
              " 'far',\n",
              " 'reaching',\n",
              " 'economic',\n",
              " 'damage',\n",
              " 'businessmen',\n",
              " 'and',\n",
              " 'officials',\n",
              " 'said',\n",
              " 'they',\n",
              " 'told',\n",
              " 'reuter',\n",
              " 'correspondents',\n",
              " 'in',\n",
              " 'asian',\n",
              " 'capitals',\n",
              " 'a',\n",
              " 'u',\n",
              " 's',\n",
              " 'move',\n",
              " 'against',\n",
              " 'japan',\n",
              " 'might',\n",
              " 'boost',\n",
              " 'protectionist',\n",
              " 'sentiment',\n",
              " 'in',\n",
              " 'the',\n",
              " 'u',\n",
              " 's',\n",
              " 'and',\n",
              " 'lead',\n",
              " 'to',\n",
              " 'curbs',\n",
              " 'on',\n",
              " 'american',\n",
              " 'imports',\n",
              " 'of',\n",
              " 'their',\n",
              " 'products',\n",
              " 'but',\n",
              " 'some',\n",
              " 'exporters',\n",
              " 'said',\n",
              " 'that',\n",
              " 'while',\n",
              " 'the',\n",
              " 'conflict',\n",
              " 'would',\n",
              " 'hurt',\n",
              " 'them',\n",
              " 'in',\n",
              " 'the',\n",
              " 'long',\n",
              " 'run',\n",
              " 'in',\n",
              " 'the',\n",
              " 'short',\n",
              " 'term',\n",
              " 'tokyo',\n",
              " 's',\n",
              " 'loss',\n",
              " 'might',\n",
              " 'be',\n",
              " 'their',\n",
              " 'gain',\n",
              " 'the',\n",
              " 'u']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = word_tokenize(' '.join(words))"
      ],
      "metadata": {
        "id": "sv2ZYgDyegQv"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the dimension of words\n",
        "print(words[0])\n",
        "len(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9gMBe0Yi9Pv",
        "outputId": "80df25c0-17d2-460d-a5cb-b72c9b27f9ad"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "asian\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1327270"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model definition (without fall-back)"
      ],
      "metadata": {
        "id": "2rSlFTQBf3Tr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NGramModel:\n",
        "    def __init__(self, n, words):\n",
        "        self.n = n\n",
        "        self.model = defaultdict(lambda: defaultdict(int))\n",
        "        self._build_model(words)\n",
        "\n",
        "    def _build_model(self, words):\n",
        "        for gram in ngrams(words, self.n):\n",
        "            context = gram[:-1]\n",
        "            word = gram[-1]\n",
        "            self.model[context][word] += 1\n",
        "\n",
        "        # Convert counts to probabilities\n",
        "        for context in self.model:\n",
        "            total = float(sum(self.model[context].values()))\n",
        "            for word in self.model[context]:\n",
        "                self.model[context][word] /= total\n",
        "\n",
        "    def get_next_word_probs(self, *context):\n",
        "        if len(context) != self.n - 1:\n",
        "            raise ValueError(f\"Expected context length {self.n - 1}, got {len(context)}\")\n",
        "\n",
        "        probs = self.model[context]\n",
        "        if probs:\n",
        "            return sorted(probs.items(), key=lambda x: x[1], reverse=True)\n",
        "        else:\n",
        "            return []"
      ],
      "metadata": {
        "id": "XdZcatASemLd"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example to show what happens in the backend during the calculation of the next word"
      ],
      "metadata": {
        "id": "WRgaROi4nAkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Build a trigram model (n=3)\n",
        "n = 3\n",
        "model = NGramModel(n, words)\n",
        "\n",
        "# Query with context ('the', 'stock')\n",
        "context = ('the', 'stock')\n",
        "predictions = model.get_next_word_probs(*context)\n",
        "\n",
        "# Output\n",
        "if predictions:\n",
        "    print(f\"Next word probabilities for context {context}:\")\n",
        "    for word, prob in predictions:\n",
        "        print(f\"{word}: {prob:.4f}\")\n",
        "else:\n",
        "    print(\"No predictions available for this context.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QCO4HovgKv_",
        "outputId": "4e546ee1-5391-49ee-9ce6-db8299ff644d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Next word probabilities for context ('the', 'stock'):\n",
            "of: 0.1009\n",
            "market: 0.0877\n",
            "for: 0.0746\n",
            "split: 0.0614\n",
            "to: 0.0395\n",
            "was: 0.0395\n",
            "exchange: 0.0351\n",
            "is: 0.0307\n",
            "price: 0.0263\n",
            "in: 0.0263\n",
            "dividend: 0.0219\n",
            "on: 0.0175\n",
            "has: 0.0175\n",
            "as: 0.0175\n",
            "and: 0.0175\n",
            "at: 0.0175\n",
            "will: 0.0132\n",
            "purchases: 0.0132\n",
            "closed: 0.0132\n",
            "jumped: 0.0132\n",
            "the: 0.0088\n",
            "based: 0.0088\n",
            "purchase: 0.0088\n",
            "from: 0.0088\n",
            "may: 0.0088\n",
            "today: 0.0088\n",
            "rose: 0.0088\n",
            "manager: 0.0044\n",
            "going: 0.0044\n",
            "coniston: 0.0044\n",
            "following: 0.0044\n",
            "dropped: 0.0044\n",
            "spectra: 0.0044\n",
            "including: 0.0044\n",
            "total: 0.0044\n",
            "nearly: 0.0044\n",
            "between: 0.0044\n",
            "collapse: 0.0044\n",
            "fall: 0.0044\n",
            "atlantis: 0.0044\n",
            "represents: 0.0044\n",
            "centronics: 0.0044\n",
            "last: 0.0044\n",
            "sales: 0.0044\n",
            "harlow: 0.0044\n",
            "after: 0.0044\n",
            "russell: 0.0044\n",
            "could: 0.0044\n",
            "under: 0.0044\n",
            "moved: 0.0044\n",
            "north: 0.0044\n",
            "should: 0.0044\n",
            "depreciation: 0.0044\n",
            "since: 0.0044\n",
            "wednesday: 0.0044\n",
            "metz: 0.0044\n",
            "fell: 0.0044\n",
            "goes: 0.0044\n",
            "subscription: 0.0044\n",
            "increased: 0.0044\n",
            "he: 0.0044\n",
            "consolidation: 0.0044\n",
            "into: 0.0044\n",
            "languished: 0.0044\n",
            "being: 0.0044\n",
            "grew: 0.0044\n",
            "through: 0.0044\n",
            "position: 0.0044\n",
            "can: 0.0044\n",
            "totaling: 0.0044\n",
            "amounts: 0.0044\n",
            "each: 0.0044\n",
            "engine: 0.0044\n",
            "traders: 0.0044\n",
            "would: 0.0044\n",
            "adjustment: 0.0044\n",
            "offering: 0.0044\n",
            "focusing: 0.0044\n",
            "it: 0.0044\n",
            "recently: 0.0044\n",
            "repurchase: 0.0044\n",
            "exchanges: 0.0044\n",
            "a: 0.0044\n",
            "s: 0.0044\n",
            "transfer: 0.0044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking if can produce a coherent sentence of given length or not"
      ],
      "metadata": {
        "id": "qGEB7Tb6g9Ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 8\n",
        "context = ('the', 'stocks', 'of')\n",
        "model = NGramModel(4, words)\n",
        "sentence = list(context)\n",
        "for _ in range(n):\n",
        "    predictions = model.get_next_word_probs(*sentence[-3:])\n",
        "    if predictions:\n",
        "        next_word = predictions[0][0]\n",
        "        sentence.append(next_word)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(' '.join(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxn16w1YnhjG",
        "outputId": "3b9736a6-bb55-453c-b2f0-76bdecff43a7"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the stocks of other textile makers rose along with burlington j\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = 8\n",
        "context = ('I ', 'feel', 'like')\n",
        "model = NGramModel(4, words)\n",
        "sentence = list(context)\n",
        "for _ in range(n):\n",
        "    predictions = model.get_next_word_probs(*sentence[-3:])\n",
        "    if predictions:\n",
        "        next_word = predictions[0][0]\n",
        "        sentence.append(next_word)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(' '.join(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBZHVDJzgltf",
        "outputId": "e8dcbe2c-a674-4a42-f477-b82057a7c6f7"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I  feel like\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We see that 'I feel like' is unable to move ahead, as it has never seen a text combination like that... we want to avoid that in the real case scenarios. We will now use interpolated N-gram model"
      ],
      "metadata": {
        "id": "cHPVmcoZnzBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InterpolatedNGramModel:\n",
        "    def __init__(self, n, words, lambdas=None):\n",
        "        self.n = n\n",
        "        self.lambdas = lambdas if lambdas else [1 / n] * n  # Equal weight default\n",
        "        self.models = [defaultdict(Counter) for _ in range(n)]\n",
        "        self.vocab = set(words)\n",
        "        self._build_models(words)\n",
        "\n",
        "    def _build_models(self, words):\n",
        "        for k in range(1, self.n + 1):\n",
        "            for gram in ngrams(words, k):\n",
        "                context = gram[:-1]\n",
        "                word = gram[-1]\n",
        "                self.models[k - 1][context][word] += 1\n",
        "\n",
        "        # Normalize to probabilities\n",
        "        for k in range(self.n):\n",
        "            for context in self.models[k]:\n",
        "                total = float(sum(self.models[k][context].values()))\n",
        "                for word in self.models[k][context]:\n",
        "                    self.models[k][context][word] /= total\n",
        "\n",
        "    def get_next_word_probs(self, *context):\n",
        "        \"\"\"\n",
        "        Returns interpolated probabilities for next words given context.\n",
        "        \"\"\"\n",
        "        if len(context) > self.n - 1:\n",
        "            context = context[-(self.n - 1):]  # Use most recent (n-1) words\n",
        "\n",
        "        scores = defaultdict(float)\n",
        "        for k in range(self.n):\n",
        "            subcontext = context[-(k):] if k > 0 else ()\n",
        "            model_k = self.models[k]\n",
        "            if subcontext in model_k:\n",
        "                for word, prob in model_k[subcontext].items():\n",
        "                    scores[word] += self.lambdas[k] * prob\n",
        "\n",
        "        # Normalize final scores (optional, but for consistency)\n",
        "        total_score = sum(scores.values())\n",
        "        if total_score > 0:\n",
        "            for word in scores:\n",
        "                scores[word] /= total_score\n",
        "\n",
        "        return sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Example usage:\n",
        "model = InterpolatedNGramModel(n=4, words=words)\n",
        "context = ('i', 'feel', 'like')\n",
        "predictions = model.get_next_word_probs(*context)\n",
        "\n",
        "# Show top 10 predictions\n",
        "for word, prob in predictions[:10]:\n",
        "    print(f\"{word}: {prob:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O61Wyjtxk2BO",
        "outputId": "8ebff42e-8fb8-4a42-e6ef-69e8768d021d"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "if: 0.5016\n",
            "to: 0.0624\n",
            "the: 0.0471\n",
            "a: 0.0211\n",
            "this: 0.0082\n",
            "in: 0.0080\n",
            "that: 0.0077\n",
            "of: 0.0069\n",
            "it: 0.0059\n",
            "other: 0.0054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = 4\n",
        "context = ('i', 'feel', 'like')\n",
        "sentence = list(context)\n",
        "for _ in range(n):\n",
        "    predictions = model.get_next_word_probs(*sentence[-3:])\n",
        "    if predictions:\n",
        "        next_word = predictions[0][0]\n",
        "        sentence.append(next_word)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(' '.join(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFLaqdZymBOC",
        "outputId": "3816fd6c-4f78-443f-fce0-9c6a4971729f"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i feel like if we didn t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5VmsAVeOqtTp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
